<!DOCTYPE HTML>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Noopur Koshta</title>
  <meta name="author" content="Noopur Koshta">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="media/self_pic.jpeg">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <!-- Header Section -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Noopur Koshta</name>
                  </p>
                  <p>I am a Masters student in the <a href="https://www.wpi.edu/academics/departments/robotics-engineering">Robotics Engineering program</a> at Worcester Polytechnic Institute (WPI). My research focuses on Visual Perception and Path Planning of Mobile Robots in Confined Spaces.</p>
                  <p>Currently, I'm exploring applications of diffusion models in world foundation models for advancing robotics capabilities. I have a strong background in algorithmic efficiency and mathematical foundations, demonstrated through logic optimization and CUDA acceleration.</p>
                  <p style="text-align:center">
                    <a href="mailto:koshta.noopur@gmail.com">Email</a> &nbsp/&nbsp
                    <a href="media/Noopur_Koshta_AIML.pdf">Resume</a> &nbsp/&nbsp
                    <a href="https://www.linkedin.com/in/noopur-koshta/">LinkedIn</a> &nbsp/&nbsp
                    <a href="https://github.com/noopur2805/">Github</a>
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="media/self_pic.jpeg"><img style="width:100%;max-width:100%" alt="profile photo" src="media/self_pic.jpeg"></a>
                </td>
              </tr>
            </tbody>
          </table>

          <!-- Professional Experience Section -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Professsional Experience</heading>
                </td>
              </tr>
            </tbody>
          </table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <!-- MER Lab -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:top">
                  <div class="one">
                    <img src='media/wpi.png' width="160">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:top">
                  <strong>Graduate Research Assistant - MER Lab</strong>
                  <br>
                  <em>January 2024 – December 2024</em>
                  <p><strong>Deep Learning-Based Visual Feature Tracking System (Mentor: Prof. Berk Calli):</strong></p>
                  <ul style="margin-top:0">
                    <li>Developed Graph Convolution Network (GCN), attaining MSE loss less than 0.4 in robot joint estimation despite visual obstructions</li>
                    <li>Accelerated joint estimation training, cutting time from 5 hours to 15 minutes per iteration</li>
                    <li>Adopted a hybrid UKF-GCN approach for robust tracking during occlusions</li>
                  </ul>
                  <p><strong>Multi-Agent Localization (Mentor: Prof. Siavash Farzan):</strong></p>
                  <ul style="margin-top:0">
                    <li>Implemented distributed EKF with Voronoi Tessellation system for warehouse automation</li>
                    <li>Developed multi-robot coordination achieving mean localization error ≤ 0.8</li>
                  </ul>
                </td>
              </tr>

              <!-- BioRobotics Lab -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:top">
                  <div class="one">
                    <img src='media/cmu.jpg' width="150">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:top">
                  <strong>Graduate Research Assistant - BioRobotics Lab</strong>
                  <br>
                  <em>March 2024 – April 2024</em>
                  <p><strong>Shape Estimation of Snake Robot (Mentor: Prof. Howie Choset):</strong></p>
                  <ul style="margin-top:0">
                    <li>Investigated forward/inverse kinematics for a surgical snake robot to enable precise 3D navigation and control during heart procedures.</li>
                  </ul>
                </td>
              </tr>
            
              <!-- Ignitarium -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:top">
                  <div class="one">
                    <a href="https://ignitarium.com/"><img src='media/Ignitarium-logo-square.png' width="160"></a>
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:top">
                  <strong>Senior AI Engineer</strong>
                  <br>
                  <em>November 2021 – June 2022</em>
                  <p><strong>Parallel Image Processing for High-Performance Computing on GPU devices:</strong></p>
                  <ul style="margin-top:0">
                    <li>Directed peers in reengineering OpenCV core algorithms into warp-optimized CUDA kernels for resource-constrained SoC devices.</li>
                    <li>Optimized GPU memory through shared and coalesced memory pattern, reducing memory bandwidth by 20% for embedded systems.</li>
                </td>
              </tr>

              <!-- Persistent -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:top">
                  <div class="one">
                    <a href="https://www.persistent.com/"><img src='media/persistent.jpg' width="160"></a>
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:top">
                  <strong>Senior Machine Learning Engineer</strong>
                  <br>
                  <em>May 2016 – April 2020</em>
                  <p><strong>Medical Image Segmentation:</strong></p>
                  <ul style="margin-top:0">
                    <li>Implemented hierarchical CNN with cascaded feature pyramids and dense connectivity, achieving 96.9% dice score in lesion segmentation.</li>
                  <p><strong>Attendance Tracking with Facial Recognition:</strong></p>
                    <li>Enhanced face detection pipeline achieving 96% accuracy in department-wide attendance monitoring system.</li>
                  <p><strong>Medical Text Summarization:</strong></p>
                    <li>Engineered LSTM architecture with clinical embeddings and self-attention, delivering 85% precision in ICD code classification.</li>
                </td>
              </tr>
            </tbody>
          </table>

          <!-- Generative AI Projects Section -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Generative AI Projects</heading>
                </td>
              </tr>
            </tbody>
          </table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <!-- LLM Safety Alignment -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:top">
                  <div class="one">
                    <img src='media/llm-safety.png' width="160">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:top">
                  <a href="https://github.com/noopur2805/llm-safety">One-Shot Safety Alignment for Large Language Models (LLMs)</a>
                  <br>
                  <a href="#">PyTorch, Transformers, RLHF</a>
                  <p>Reproducing MOCAN/PECAN algorithms from published research to validate proposed computational efficiency gains in RLHF for LLM safety alignment.</p>
                </td>
              </tr>
            </tbody>
          </table>

          <!-- Deep Learning Projects Section -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Deep Learning Projects</heading>
                </td>
              </tr>
            </tbody>
          </table>

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <!-- Vision Transformers -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:top">
                  <div class="one">
                    <img src='media/transformer.png' width="160">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:top">
                  <a href="https://github.com/noopur2805/vision-transformers">Exploring Query-Key Relationships in Vision Transformers Through SVD</a>
                  <br>
                  <a href="#">PyTorch, NumPy, Attention Analysis</a>
                  <p>Reproducing research on transformer interpretability methodology analyzing self-attention singular modes to understand feature direction interactions.</p>
                </td>
              </tr>

              <!-- Deep Q-Learning -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:top">
                  <div class="one">
                    <img src='media/breakout.gif' width="160">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:top">
                  <a href="https://github.com/noopur2805/CS525_Reinforcement_Learning/tree/main/BreakoutRL">Deep Q-Learning for Reward Optimization in Atari Breakout Game</a>
                  <br>
                  <a href="#">Python, PyTorch, OpenAI Gym</a>
                  <p>Analyzed Deep Q-Network (DQN) architecture implementation for Atari Breakout, examining agent performance across 120,000 episodes to achieve a score of 91.</p>
                </td>
              </tr>

              <!-- 3D Scene Reconstruction -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:top">
                  <div class="one">
                    <img src='media/lego.gif' width="160">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:top">
                  <a href="https://github.com/noopur2805/RBE_549_Computer_Vision/tree/main/SfM%20and%20NerF">3D Scene Reconstruction with Structure from Motion (SfM)</a>
                  <br>
                  <a href="#">PyTorch, OpenCV, NeRF</a>
                  <p>Developed 3D reconstruction using Epipolar Geometry and Perspective-n-Point (PnP) with cheirality constraints, achieving 0.98 MSE in camera pose estimation.</p>
                </td>
              </tr>

              <!-- Multi-Sensor Fusion -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:top">
                  <div class="one">
                    <img src='media/ukf_highway_tracked.gif' width="160">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:top">
                  <a href="https://github.com/noopur2805/SFND_Unscented_Kalman_Filter">Multi-Sensor Fusion for Autonomous Driving</a>
                  <br>
                  <a href="#">C++, Python, ROS, Kalman Filters</a>
                  <p>Engineered sensor fusion pipeline (LiDAR, radar, camera) with UKF-based multi-object tracking, achieving ≤ 0.6 MSE for surrounding vehicle localization.</p>
                </td>
              </tr>

              <!-- Visual Inertial Odometry -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:top">
                  <div class="one">
                    <img src='media/VIOTraj.png' width="160">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:top">
                  <a href="https://github.com/noopur2805/RBE_549_Computer_Vision/tree/main/Visual%20Inertial%20Odometry">Visual Inertial Odometry</a>
                  <br>
                  <a href="#">Python, TensorFlow, Kalman Filters</a>
                  <p>6-DOF state estimation using filter-based stereo visual inertial odometry with Multi-State Constraint Kalman Filter (MSCKF), achieving RMSE of 0.17. Trained CNN-LSTM network on synchronized visual and inertial EuROC data with 98.2% trajectory overlap.</p>
                </td>
              </tr>

              <!-- Zhang's Camera Calibration -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:top">
                  <div class="one">
                    <img src='media/checkerboard.jpg' width="160">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:top">
                  <a href="https://github.com/noopur2805/RBE_549_Computer_Vision/tree/main/AutoCalib%20(Camera%20Calibration)">Zhang's Camera Calibration</a>
                  <br>
                  <a href="#">Python, NumPy, OpenCV</a>
                  <p>Implemented Microsoft's Zhengyou Zhang's 1998 camera calibration method using eigen decomposition for solving homogeneous linear equations and MLE for optimization, achieving mean re-projection error of 0.5 pixels.</p>
                </td>
              </tr>

              <!-- Panorama Stitching -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:top">
                  <div class="one">
                    <img src='media/panorama.png' width="160">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:top">
                  <a href="https://github.com/noopur2805/RBE_549_Computer_Vision/tree/main/AutoPano%20(Panoroma%20Stitching)">Panorama Stitching</a>
                  <br>
                  <a href="#">Python, OpenCV, PyTorch</a>
                  <p>Developed panorama stitching system using adaptive non-maximal suppression for uniform feature detection and RANSAC for outlier removal. Implemented HomographyNet CNN architecture for homography estimation using synthetic data.</p>
                </td>
              </tr>

              <!-- Probability-based Edge Detection -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:top">
                  <div class="one">
                    <img src='media/pblite.jpg' width="160">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:top">
                  <a href="https://github.com/noopur2805/RBE_549_Computer_Vision/tree/main/Alohmora%20(Probability%20based%20edge%20detection)">Probability-based Edge Detection</a>
                  <br>
                  <a href="#">Python, NumPy, Scikit-image</a>
                  <p>Created simplified pb-lite edge detection system analyzing texture and color discontinuities across multiple scales, outperforming classical Canny and Sobel methods in textured regions.</p>
                </td>
              </tr>

              <!-- Pick-and-Place Robot -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:top">
                  <div class="one">
                    <img src='media/homebot.gif' width="160">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:top">
                  <a href="https://github.com/noopur2805/Home-Service-Robot">Pick-and-Place Robot</a>
                  <br>
                  <a href="#">ROS, C++, SLAM</a>
                  <p>Developed ROS-based pick-and-place robot simulation using RTAB mapping for region recognition and loop closure detection through bag-of-words approach.</p>
                </td>
              </tr>
            </tbody>
          </table>
          
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Motion Planning Projects</heading>
                </td>
              </tr>
            </tbody>
          </table>

          <!-- Motion Planning Projects Section -->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <!-- Kinematic Planning -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:top">
                  <div class="one">
                    <img src='media/akerman.png' width="160">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:top">
                  <a href="https://github.com/noopur2805/RBE_550_Motion_Planning/tree/main/Valet">Kinematic Planning under Non-holonomic Constraints</a>
                  <br>
                  <a href="#">Python, ROS, Motion Planning</a>
                  <p>Developed kinematic path planner handling non-holonomic constraints for automated parking of various vehicle types from differential drive robots to cars with trailers.</p>
                </td>
              </tr>

              <!-- Graph Search Algorithms -->
              <tr>
                <td style="padding:20px;width:25%;vertical-align:top">
                  <div class="one">
                    <img src='media/flatland.png' width="160">
                  </div>
                </td>
                <td style="padding:20px;width:75%;vertical-align:top">
                  <a href="https://github.com/noopur2805/RBE_550_Motion_Planning/tree/main/FlatLand">Graph Search Algorithms Implementation</a>
                  <br>
                  <a href="#">Python, Matplotlib</a>
                  <p>Implemented and compared BFS, DFS, and Dijkstra's algorithms on configurable grid world environments with variable obstacle density.</p>
                </td>
              </tr>
            </tbody>
          </table>
          
        </td>
      </tr>
    </tbody>
  </table>
</body>
</html>
